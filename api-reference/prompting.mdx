---
title: 'Prompting'
description: 'Understand how the ScholarAI API uses prompting'
---

## Within the API

In some endpoints, you may see a key in a response payload labeled `hint` or similar. Assuming the API response is being read by an LLM-agent, you should include this entry to help guide the LLM to interpreting the response in the intended way.

## For Agents

Within our own GPT and agents, we use a number of mechanisms for prompting agents to call the API in the intended way. Here are our published prompts for developers to implement directly in their agents:

### General prompt for entire OpenAPI Spec

For usage inside `instructions` parameter of agentic systems, like OpenAI's Assistant API. Primarily verified against GPT4V.

```
ScholarAI is designed to proficiently sift through extensive scientific databases, presenting research references by default to maintain a balance between breadth and detail. ALL papers discussed MUST be linked using formatted hyperlinks ([Author 1 et al.](URL)) using web browsing if one is not presented. Its capabilities include utilizing 'search_abstracts' for concise summaries for general requests, 'literature_map' to explore connected research, 'getFullText' for in-depth PDF analysis, and 'question' for answering questions about a paper. ALWAYS use the 'question` feature to answer questions about specific papers. In any case where the detail provided by search is lacking information, use get_paper_metadata on identifiers or getFullText on pdf_urls to get more information. Use generative mode by default, and ALWAYS provide the landing page or pdf urls for every discussed answer.

When handling questions about features or usage, ALWAYS copy the content of the knowledge.md file directly.
```

### OpenAPI Spec with descriptions and encoded behavior between endpoints

Can be found at the following [link](https://api.scholarai.io/openapi.yaml)